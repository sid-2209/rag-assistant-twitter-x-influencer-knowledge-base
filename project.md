
# ğŸ¦ Twitter/X Influencer Knowledge Base (RAG Assistant)

## ğŸ¯ Overview
The **Twitter/X Influencer Knowledge Base Assistant** is an AI-powered **Retrieval-Augmented Generation (RAG)** system that helps users discover and query information about influencers across domains such as **AI, fashion, gaming, fitness, and memes**.  

It ingests influencer data, builds a vector database, and answers questions with citations, ensuring that responses are both **accurate** and **attributable** to real influencers.  

---

## âœ… Features
- ğŸ” **Data Ingestion Pipeline**: Collects and processes influencer data (profiles, niches, posts).  
- ğŸ§  **Vector Search**: Embeds influencer data using OpenAI embeddings & stores in FAISS/Chroma.  
- ğŸ¤– **RAG Engine**: Combines vector retrieval with LLMs (GPT-4o-mini/GPT-5).  
- ğŸ“œ **Citations**: Always references influencer names & handles.  
- ğŸŒ **API**: FastAPI-powered REST endpoints for queries.  
- ğŸ§ª **Testing**: Pytest coverage for RAG, vector search, and API.  
- ğŸ“¦ **Infra**: Docker + docker-compose for easy deployment.  
- ğŸš€ **Deployable**: Works locally and on cloud (AWS/GCP/Render).  

---

## ğŸ—ï¸ Project Structure
```
twitter-influencer-assistant/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api.py          # FastAPI entrypoint
â”‚   â”œâ”€â”€ routes.py       # Mock routes mounted under /mock
â”‚   â”œâ”€â”€ config.py       # settings management
â”‚   â”œâ”€â”€ embeddings.py   # embedding logic
â”‚   â”œâ”€â”€ pipeline.py     # ETL pipeline (raw â†’ processed â†’ vector DB)
â”‚   â”œâ”€â”€ rag.py          # RAG orchestration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # raw influencer data
â”‚   â”œâ”€â”€ processed/      # cleaned dataset
â”‚   â””â”€â”€ sample.json
â”œâ”€â”€ models/             # vector DB storage
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_rag.py
â”‚   â”œâ”€â”€ test_vector.py
â”‚   â””â”€â”€ conftest.py
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ infra/requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
```

---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone Repository
```bash
git clone https://github.com/yourusername/twitter-influencer-assistant.git
cd twitter-influencer-assistant
```

### 2ï¸âƒ£ Create Virtual Environment
```bash
python -m venv .venv
source .venv/bin/activate   # macOS/Linux
.venv\Scripts\activate    # Windows
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r infra/requirements.txt
```

### 4ï¸âƒ£ Setup Environment Variables
Create a `.env` file:
```ini
OPENAI_API_KEY=your_openai_api_key_here
```

### 5ï¸âƒ£ Run Pipeline
```bash
python app/pipeline.py
```

### 6ï¸âƒ£ Start API Server
```bash
uvicorn app.api:app --reload
```

API will be live at: `http://127.0.0.1:8000`  

---

## ğŸŒ API Endpoints

### **1. Health Check**
```http
GET /healthz
```
âœ… Returns service status.  

### **2. Query Influencers**
```http
POST /query
Content-Type: application/json

{
  "query": "Who are top AI influencers on Twitter?"
}
```
ğŸ”„ Response:
```json
{
  "answer": "Some of the top AI influencers include Jane Doe (@janedoe)...",
  "citations": ["Jane Doe (@janedoe)", "John AI (@john_ai)"]
}
```

---

### Mock/demo routes

```http
POST /mock/query
```

Demo endpoint using static mock docs from `app/routes.py` for quick testing. This does not use the vector store and is mounted under `/mock` to avoid conflicts with the primary `/query` endpoint.

---

## ğŸ§ª Testing
Run all tests:
```bash
pytest -q
```

Test files:
- `test_rag.py`: Validates RAG context building & fallback.  
- `test_vector.py`: Ensures vector retrieval works correctly.  
- `test_api.py`: End-to-end API tests.  

---

## ğŸ“¦ Deployment

### Docker
```bash
docker build -t twitter-assistant .
docker run -p 8000:8000 twitter-assistant
```

### Docker Compose
```bash
docker-compose up --build
```

### Cloud Deployment
- âœ… **Render / GCP Cloud Run / AWS ECS** (lightweight FastAPI service).  
- Use secrets manager for `OPENAI_API_KEY`.  

---

## ğŸ¨ (Optional) UI Layer
- Build a **Streamlit app** or **Next.js frontend**.  
- Allow users to type queries & display influencer profile cards with citations.  

---

## ğŸ“ˆ Extensions (Future Work)
- ğŸ”¢ Analytics: track most-cited influencers.  
- ğŸ“· Multimodal: include profile pics with CLIP embeddings.  
- ğŸ·ï¸ Fine-tuning: adapt LLM for influencer Q&A style.  
- ğŸ“Š Evaluation: Compare RAG vs vanilla GPT responses.  

---

## ğŸ“œ Deliverables
- âœ… Codebase with clean structure.  
- âœ… REST API (FastAPI).  
- âœ… Tests with pytest.  
- âœ… Dockerized app, cloud-ready.  
- âœ… Documentation (this README).  

---

## ğŸ‘¨â€ğŸ’» Author
Built with â¤ï¸ by [Your Name]  
For questions: open an issue or reach out on [LinkedIn/GitHub].
